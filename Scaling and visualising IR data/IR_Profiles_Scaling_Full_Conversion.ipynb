{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c211e3a1-70a3-4d18-ad35-e942a367aaca",
   "metadata": {},
   "source": [
    "# Scripts for Scaling IR Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae4846-7551-4601-b6b1-e3e35592067b",
   "metadata": {},
   "source": [
    "### Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de64eb88-2158-4866-afdf-3418da4d6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, time as datetime_time\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21411ae-3e51-40af-abbc-3f05500a1c59",
   "metadata": {},
   "source": [
    "### Small Functions Used in Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b7ca492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_time_to_seconds(time_value):\n",
    "    if isinstance(time_value, str):  # If time is a string\n",
    "        try:\n",
    "            # Handle \"HH:MM:SS\" or \"HH:MM:SS.S\" format (with or without fractional seconds)\n",
    "            if len(time_value.split(\":\")) == 3:\n",
    "                try:\n",
    "                    # First, try to parse with fractional seconds\n",
    "                    time_obj = datetime.strptime(time_value, '%H:%M:%S.%f')\n",
    "                except ValueError:\n",
    "                    # If that fails, try parsing without fractional seconds\n",
    "                    time_obj = datetime.strptime(time_value, '%H:%M:%S')\n",
    "                return timedelta(hours=time_obj.hour, minutes=time_obj.minute, seconds=time_obj.second, microseconds=time_obj.microsecond).total_seconds()\n",
    "\n",
    "            # Handle \"MM:SS\" or \"MM:SS.S\" format (with or without fractional seconds)\n",
    "            elif len(time_value.split(\":\")) == 2:\n",
    "                try:\n",
    "                    # First, try to parse with fractional seconds\n",
    "                    time_obj = datetime.strptime(time_value, '%M:%S.%f')\n",
    "                except ValueError:\n",
    "                    # If that fails, try parsing without fractional seconds\n",
    "                    time_obj = datetime.strptime(time_value, '%M:%S')\n",
    "                return timedelta(minutes=time_obj.minute, seconds=time_obj.second, microseconds=time_obj.microsecond).total_seconds()\n",
    "        \n",
    "        except ValueError:\n",
    "            return np.nan  # Handle invalid formats\n",
    "    \n",
    "    elif isinstance(time_value, datetime.time):  # If time is already a datetime.time object\n",
    "        return timedelta(hours=time_value.hour, minutes=time_value.minute, seconds=time_value.second, microseconds=time_value.microsecond).total_seconds()\n",
    "    \n",
    "    return np.nan  # Return NaN for anything else\n",
    "\n",
    "def datetime_to_seconds(value):\n",
    "    \"\"\"\n",
    "    Convert a single time or datetime value to total seconds.\n",
    "    Handles datetime.datetime, datetime.time, and strings.\n",
    "    \"\"\"\n",
    "    if isinstance(value, datetime):\n",
    "        # If the value is a datetime object, calculate total seconds from the first time in the series\n",
    "        base_date = datetime(1900, 1, 1)  # Start counting from the \"start\" date\n",
    "        total_seconds = (value - base_date).total_seconds()\n",
    "    elif isinstance(value, str):\n",
    "        # Parse the string into a datetime object, with two possible formats\n",
    "        try:\n",
    "            # Try time-only format: \"HH:MM:SS.sss\"\n",
    "            dt_value = datetime.strptime(value, \"%H:%M:%S.%f\")\n",
    "        except ValueError:\n",
    "            # If the time-only parsing fails, try full datetime format: \"YYYY-MM-DD HH:MM:SS.sss\"\n",
    "            dt_value = datetime.strptime(value, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        \n",
    "        # In either case, we treat the full datetime as starting from base_date (1900-01-01)\n",
    "        base_date = datetime(1900, 1, 1)\n",
    "        total_seconds = (dt_value - base_date).total_seconds()\n",
    "    elif isinstance(value, time):\n",
    "        # If the value is a time object, treat it as relative to the start of the first day\n",
    "        base_time = datetime.strptime(\"00:00:00.000000\", \"%H:%M:%S.%f\")  # Reference to start of the first day\n",
    "        total_seconds = (datetime.combine(datetime(1900, 1, 1), value) - base_time).total_seconds()\n",
    "    elif isinstance(value, timedelta):\n",
    "        # If it's a timedelta object, just extract total seconds directly\n",
    "        total_seconds = value.total_seconds()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported type: {type(value)}\")\n",
    "    \n",
    "    return total_seconds\n",
    "\n",
    "def convert_time_to_seconds(time_series):\n",
    "    # Apply the conversion function to each element in the series\n",
    "    times_2=time_series.apply(datetime_to_seconds)\n",
    "    times_corrected=[]\n",
    "    day_counter=0\n",
    "    for i,j in enumerate(times_2):\n",
    "        if i!=0 and times_2[i]<times_2[i-1]:\n",
    "            day_counter+=1\n",
    "        times_corrected.append(j+24*60*60*day_counter)\n",
    "    return pd.Series(times_corrected)\n",
    "\n",
    "# Function to dynamically detect which column is starting material and which is product based on trends\n",
    "def detect_starting_material_and_product(ir_starting_material, ir_product):\n",
    "    # Check initial and final trends for both columns\n",
    "    if ir_starting_material.iloc[0] > ir_starting_material.iloc[-1]:\n",
    "        # If starting material is decreasing, it is the starting material\n",
    "        starting_material_ir = ir_starting_material\n",
    "        product_ir = ir_product\n",
    "    else:\n",
    "        # Otherwise, product is increasing and starting material is increasing\n",
    "        starting_material_ir = ir_product\n",
    "        product_ir = ir_starting_material\n",
    "\n",
    "    return starting_material_ir, product_ir\n",
    "\n",
    "# Function to process the IR data for starting material and product\n",
    "def process_ir_data(time_in_seconds, ir_starting_material, ir_product, reaction_start_time, ir_start_time, initial_conc_starting_material, initial_conc_second_material,Name_SM1,Name_SM2,ArCl=False):\n",
    "    # Convert IR start time to seconds\n",
    "    ir_start_seconds = convert_string_time_to_seconds(ir_start_time)\n",
    "    # Convert reaction start time to seconds\n",
    "    reaction_start_seconds = convert_string_time_to_seconds(reaction_start_time)\n",
    "    \n",
    "    # Calculate time difference between reaction start and IR experiment start (in seconds)\n",
    "    time_difference = reaction_start_seconds - ir_start_seconds\n",
    "\n",
    "    print(\"Time difference between IR start and reaction start (in seconds):\", time_difference)\n",
    "    \n",
    "    # Convert the time column to seconds and adjust it by subtracting the time difference\n",
    "    \n",
    "    adjusted_time_in_seconds = time_in_seconds + time_difference\n",
    "    \n",
    "    # Convert adjusted time to minutes\n",
    "    time_in_minutes = adjusted_time_in_seconds / 60\n",
    "\n",
    "    # Calculate the time after addition\n",
    "    time_after_addition_minutes = time_in_minutes\n",
    "    print(\"Time after addition in minutes:\", time_after_addition_minutes)\n",
    "    \n",
    "    # Convert IR data columns to numeric, handle invalid data with NaN\n",
    "    ir_starting_material = pd.to_numeric(ir_starting_material, errors='coerce')\n",
    "    ir_product = pd.to_numeric(ir_product, errors='coerce')\n",
    "\n",
    "    # Dynamically detect which column is the starting material and which is the product\n",
    "    starting_material_ir, product_ir = detect_starting_material_and_product(ir_starting_material, ir_product)\n",
    "    \n",
    "    # Process starting material IR trend\n",
    "    avg_final_starting_material_ir = np.mean(starting_material_ir[-10:])  # average final 10 values\n",
    "    \n",
    "    # Get the last 3 values of starting material IR before the reaction started (time_after_addition_minutes < 0)\n",
    "    print('time',time_after_addition_minutes)\n",
    "    print( starting_material_ir[time_after_addition_minutes < 0])\n",
    "    \n",
    "    valid_starting_material_before_reaction = starting_material_ir[time_after_addition_minutes < 0].tail(3).values\n",
    "    print('Starting Material IR before reaction:', valid_starting_material_before_reaction)\n",
    "    if len(valid_starting_material_before_reaction) < 3:\n",
    "        raise ValueError(\"There are less than 3 valid values before the reaction started. Please check your data.\")\n",
    "    \n",
    "    # Ensure no NaN values before averaging\n",
    "    if np.isnan(valid_starting_material_before_reaction).any():\n",
    "        raise ValueError(\"Starting material IR contains NaN values before the reaction starts. Please check your data.\")\n",
    "    \n",
    "    # Average the last 3 values before reaction (when adjusted time is negative)\n",
    "    avg_initial_starting_material_ir = np.mean(valid_starting_material_before_reaction)\n",
    "\n",
    "    if pd.isna(avg_initial_starting_material_ir) or avg_initial_starting_material_ir == 0:\n",
    "        raise ValueError(f\"Invalid initial starting material IR average: NaN or zero detected.\\n\"\n",
    "                         f\"Avg Initial IR: {avg_initial_starting_material_ir}\")\n",
    "\n",
    "    avg_initial_starting_material_ir = float(avg_initial_starting_material_ir)\n",
    "    initial_conc_starting_material = float(initial_conc_starting_material)\n",
    "    \n",
    "    # Perform the scaling operation for starting material IR\n",
    "    scaled_starting_material_ir = (starting_material_ir - avg_final_starting_material_ir) * (initial_conc_starting_material / (avg_initial_starting_material_ir - avg_final_starting_material_ir))\n",
    "    print('Scaled Starting Material IR:', scaled_starting_material_ir)\n",
    "    \n",
    "    # Process product IR trend\n",
    "    valid_product_before_reaction = product_ir[time_after_addition_minutes < 0].tail(3)\n",
    "    if valid_product_before_reaction.isnull().any():\n",
    "        raise ValueError(\"Product IR contains NaN values before the reaction starts. Please check your data.\")\n",
    "\n",
    "    avg_initial_product_ir = np.mean(valid_product_before_reaction)\n",
    "    print('avg_initial_product_ir:', avg_initial_product_ir)\n",
    "    \n",
    "    avg_final_product_ir = np.mean(product_ir[-10:])\n",
    "    print('avg_final_product_ir:', avg_final_product_ir)\n",
    "    \n",
    "    if pd.isna(avg_final_product_ir) or avg_final_product_ir == 0:\n",
    "        raise ValueError(\"Invalid final product IR average: NaN or zero detected.\")\n",
    "\n",
    "    scaled_product_ir = (product_ir - avg_initial_product_ir) * (initial_conc_starting_material / (avg_final_product_ir - avg_initial_product_ir))\n",
    "\n",
    "    # Create DataFrame for Sheet 1 (raw IR data with time adjustments)\n",
    "    sheet1_data = pd.DataFrame({\n",
    "        'Time (HH:MM:SS)': time_in_seconds/60,  # Keeping the original time string or time object\n",
    "        'Time (minutes)': time_in_minutes,\n",
    "        'Time after addition (minutes)': time_after_addition_minutes,\n",
    "        'Starting Material IR': starting_material_ir,\n",
    "        'Product IR': product_ir\n",
    "    })\n",
    "\n",
    "    # Create DataFrame for Sheet 2 (processed starting material and product profiles)\n",
    "    sheet2_data = pd.DataFrame({\n",
    "        'Time after addition (minutes)': time_after_addition_minutes,\n",
    "        'Scaled Starting Material IR': scaled_starting_material_ir,\n",
    "        'Scaled Product IR': scaled_product_ir\n",
    "    })\n",
    "\n",
    "    # Concentration profile for the second starting material\n",
    "    if initial_conc_second_material!=None:\n",
    "        second_material_concentration = initial_conc_second_material - scaled_product_ir\n",
    "        if ArCl:\n",
    "            second_material_concentration_free = initial_conc_second_material - scaled_product_ir*2\n",
    "        #print('Second Material Concentration:', second_material_concentration)\n",
    "\n",
    "    negative_time_indices = time_after_addition_minutes[time_after_addition_minutes < 0].index\n",
    "\n",
    "    # Create DataFrame for Sheet 3 (concentration profiles)\n",
    "    times_final_sheet=np.delete(time_after_addition_minutes, negative_time_indices[:-1])\n",
    "    times_final_sheet[0]=0\n",
    "    SM1_final_sheet=np.delete(scaled_starting_material_ir, negative_time_indices[:-1])\n",
    "    SM1_final_sheet[0]=initial_conc_starting_material\n",
    "    P_final_sheet=np.delete(scaled_product_ir, negative_time_indices[:-1])\n",
    "    P_final_sheet[0]=0\n",
    "    if initial_conc_second_material!=None:\n",
    "        SM2_final_sheet=np.delete(second_material_concentration, negative_time_indices[:-1])\n",
    "        SM2_final_sheet[0]=initial_conc_second_material\n",
    "        if ArCl:\n",
    "            SM2_final_sheet_free=np.delete(second_material_concentration_free, negative_time_indices[:-1])\n",
    "            SM2_final_sheet_free[0]=initial_conc_second_material\n",
    "    MB=SM1_final_sheet+P_final_sheet\n",
    "    if initial_conc_second_material!=None:\n",
    "        if ArCl:\n",
    "            sheet3_data = pd.DataFrame({\n",
    "                'Time / min': times_final_sheet,\n",
    "                'Starting Material':SM1_final_sheet ,\n",
    "                'Product': P_final_sheet,\n",
    "                'Second Starting Material': SM2_final_sheet,\n",
    "                'Second Starting Material free': SM2_final_sheet_free,\n",
    "                'Mass Balance': MB\n",
    "            })\n",
    "        else:\n",
    "            sheet3_data = pd.DataFrame({\n",
    "                'Time / min': times_final_sheet,\n",
    "                'Starting Material':SM1_final_sheet ,\n",
    "                'Product': P_final_sheet,\n",
    "                'Second Starting Material': SM2_final_sheet,\n",
    "                'Mass Balance': MB\n",
    "            })\n",
    "    else:\n",
    "            sheet3_data = pd.DataFrame({\n",
    "                'Time / min': times_final_sheet,\n",
    "                'Starting Material':SM1_final_sheet ,\n",
    "                'Product': P_final_sheet,\n",
    "                'Mass Balance': MB\n",
    "            })\n",
    "    if Name_SM1 not in ['',None]:\n",
    "        sheet3_data.rename(columns={'Starting Material': Name_SM1},inplace=True)\n",
    "    if Name_SM2 not in ['',None] and initial_conc_second_material!=None:\n",
    "        sheet3_data.rename(columns={'Second Starting Material': Name_SM2},inplace=True)\n",
    "        if ArCl:\n",
    "            sheet3_data.rename(columns={'Second Starting Material free': Name_SM2+'free'},inplace=True)\n",
    "            \n",
    "    return sheet1_data, sheet2_data, sheet3_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7da1fb33-99b9-4886-9414-b4a172ce2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def convert_string_time_to_seconds(time_value):\n",
    "    \"\"\"\n",
    "    Convert a time string (e.g., 'HH:MM:SS' or 'MM:SS') or a datetime.time object to seconds.\n",
    "    Returns NaN if the format is unrecognized.\n",
    "    \"\"\"\n",
    "    if isinstance(time_value, str):\n",
    "        try:\n",
    "            parts = time_value.split(\":\")\n",
    "            if len(parts) == 3:\n",
    "                try:\n",
    "                    time_obj = datetime.strptime(time_value, '%H:%M:%S.%f')\n",
    "                except ValueError:\n",
    "                    time_obj = datetime.strptime(time_value, '%H:%M:%S')\n",
    "                return timedelta(hours=time_obj.hour, minutes=time_obj.minute, seconds=time_obj.second, microseconds=time_obj.microsecond).total_seconds()\n",
    "            elif len(parts) == 2:\n",
    "                try:\n",
    "                    time_obj = datetime.strptime(time_value, '%M:%S.%f')\n",
    "                except ValueError:\n",
    "                    time_obj = datetime.strptime(time_value, '%M:%S')\n",
    "                return timedelta(minutes=time_obj.minute, seconds=time_obj.second, microseconds=time_obj.microsecond).total_seconds()\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "    elif isinstance(time_value, time):\n",
    "        return timedelta(hours=time_value.hour, minutes=time_value.minute, seconds=time_value.second, microseconds=time_value.microsecond).total_seconds()\n",
    "    return np.nan\n",
    "\n",
    "\n",
    "def datetime_to_seconds(value):\n",
    "    \"\"\"\n",
    "    Convert a datetime, time, timedelta, or string representation into total seconds.\n",
    "    Raises ValueError on unsupported types.\n",
    "    \"\"\"\n",
    "    if isinstance(value, datetime):\n",
    "        base_date = datetime(1900, 1, 1)\n",
    "        return (value - base_date).total_seconds()\n",
    "    elif isinstance(value, str):\n",
    "        try:\n",
    "            dt_value = datetime.strptime(value, \"%H:%M:%S.%f\")\n",
    "        except ValueError:\n",
    "            dt_value = datetime.strptime(value, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        return (dt_value - datetime(1900, 1, 1)).total_seconds()\n",
    "    elif isinstance(value, time):\n",
    "        return timedelta(hours=value.hour, minutes=value.minute, seconds=value.second, microseconds=value.microsecond).total_seconds()\n",
    "    elif isinstance(value, timedelta):\n",
    "        return value.total_seconds()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported type: {type(value)}\")\n",
    "\n",
    "\n",
    "def convert_time_to_seconds(time_series):\n",
    "    \"\"\"\n",
    "    Converts a pandas Series of datetime/time values to seconds,\n",
    "    adjusting for day changes in multi-day experiments.\n",
    "    \"\"\"\n",
    "    times_in_seconds = time_series.apply(datetime_to_seconds)\n",
    "    corrected_times = []\n",
    "    day_counter = 0\n",
    "    for i, current_time in enumerate(times_in_seconds):\n",
    "        if i > 0 and current_time < times_in_seconds[i - 1]:\n",
    "            day_counter += 1\n",
    "        corrected_times.append(current_time + 24 * 3600 * day_counter)\n",
    "    return pd.Series(corrected_times)\n",
    "\n",
    "\n",
    "def detect_starting_material_and_product(ir1, ir2):\n",
    "    \"\"\"\n",
    "    Automatically determine which signal corresponds to starting material based on trends.\n",
    "    Assumes starting material decreases and product increases over time.\n",
    "    \"\"\"\n",
    "    if ir1.iloc[0] > ir1.iloc[-1]:\n",
    "        return ir1, ir2\n",
    "    return ir2, ir1\n",
    "\n",
    "\n",
    "def process_ir_data(time_in_seconds, ir_sm, ir_p, reaction_start_time, ir_start_time,\n",
    "                    conc_sm1, conc_sm2, name_sm1, name_sm2, time_original, ArCl=False):\n",
    "    \"\"\"\n",
    "    Process IR data by aligning with reaction start, scaling based on known concentrations,\n",
    "    and returning raw and processed datasets for plotting or export.\n",
    "    \"\"\"\n",
    "    # Convert reference time points\n",
    "    ir_start_sec = convert_string_time_to_seconds(ir_start_time)\n",
    "    reaction_start_sec = convert_string_time_to_seconds(reaction_start_time)\n",
    "    time_diff = reaction_start_sec - ir_start_sec\n",
    "    print(\"Time difference between IR start and reaction start (in seconds):\", time_diff)\n",
    "\n",
    "    # Adjust times and convert to minutes\n",
    "    adjusted_time = time_in_seconds + time_diff\n",
    "    time_minutes = adjusted_time / 60\n",
    "    #print(\"Adjusted time in minutes:\", time_minutes)\n",
    "\n",
    "    # Convert IR columns to numeric\n",
    "    ir_sm = pd.to_numeric(ir_sm, errors='coerce')\n",
    "    ir_p = pd.to_numeric(ir_p, errors='coerce')\n",
    "\n",
    "    # Detect correct SM and product traces\n",
    "    sm_ir, p_ir = detect_starting_material_and_product(ir_sm, ir_p)\n",
    "\n",
    "    # Baseline values\n",
    "    avg_final_sm_ir = sm_ir[-10:].mean()\n",
    "    valid_sm_before = sm_ir[time_minutes < 0].tail(3).dropna()\n",
    "    if len(valid_sm_before) < 3:\n",
    "        raise ValueError(\"Not enough valid starting material IR values before reaction.\")\n",
    "    avg_init_sm_ir = valid_sm_before.mean()\n",
    "\n",
    "    if pd.isna(avg_init_sm_ir) or avg_init_sm_ir == 0:\n",
    "        raise ValueError(\"Invalid starting material IR average.\")\n",
    "\n",
    "    # Scale starting material IR\n",
    "    sm_scaled = (sm_ir - avg_final_sm_ir) * (float(conc_sm1) / (avg_init_sm_ir - avg_final_sm_ir))\n",
    "\n",
    "    # Scale product IR\n",
    "    valid_p_before = p_ir[time_minutes < 0].tail(3).dropna()\n",
    "    avg_init_p_ir = valid_p_before.mean()\n",
    "    avg_final_p_ir = p_ir[-10:].mean()\n",
    "    if pd.isna(avg_final_p_ir) or avg_final_p_ir == 0:\n",
    "        raise ValueError(\"Invalid final product IR average.\")\n",
    "    p_scaled = (p_ir - avg_init_p_ir) * (float(conc_sm1) / (avg_final_p_ir - avg_init_p_ir))\n",
    "\n",
    "    # Sheet 1: Raw data\n",
    "    sheet1 = pd.DataFrame({\n",
    "        'Time (HH:MM:SS)': time_original,\n",
    "        'Time (minutes)': time_in_seconds / 60,\n",
    "        'Time after addition (minutes)': time_minutes,\n",
    "        'Starting Material IR': sm_ir,\n",
    "        'Product IR': p_ir\n",
    "    })\n",
    "\n",
    "    # Sheet 2: Scaled profiles\n",
    "    sheet2 = pd.DataFrame({\n",
    "        'Time after addition (minutes)': time_minutes,\n",
    "        'Scaled Starting Material IR': sm_scaled,\n",
    "        'Scaled Product IR': p_scaled\n",
    "    })\n",
    "\n",
    "    # Compute second material concentration if given\n",
    "    if conc_sm2 is not None:\n",
    "        sm2_conc = float(conc_sm2) - p_scaled\n",
    "        if ArCl:\n",
    "            sm2_free = float(conc_sm2) - 2 * p_scaled\n",
    "\n",
    "    # Prepare Sheet 3: Filter out all but last negative time point (set as zero)\n",
    "    neg_indices = time_minutes[time_minutes < 0].index\n",
    "    times_final = np.delete(time_minutes, neg_indices[:-1])\n",
    "    times_final[0] = 0\n",
    "    sm_final = np.delete(sm_scaled, neg_indices[:-1])\n",
    "    sm_final[0] = float(conc_sm1)\n",
    "    p_final = np.delete(p_scaled, neg_indices[:-1])\n",
    "    p_final[0] = 0\n",
    "    mb = sm_final + p_final\n",
    "\n",
    "    if conc_sm2 is not None:\n",
    "        sm2_final = np.delete(sm2_conc, neg_indices[:-1])\n",
    "        sm2_final[0] = float(conc_sm2)\n",
    "        if ArCl:\n",
    "            sm2_free_final = np.delete(sm2_free, neg_indices[:-1])\n",
    "            sm2_free_final[0] = float(conc_sm2)\n",
    "\n",
    "    # Build sheet 3 DataFrame\n",
    "    columns = {\n",
    "        'Time / min': times_final,\n",
    "        'Starting Material': sm_final,\n",
    "        'Product': p_final,\n",
    "        'Mass Balance': mb\n",
    "    }\n",
    "\n",
    "    if conc_sm2 is not None:\n",
    "        columns['Second Starting Material'] = sm2_final\n",
    "        if ArCl:\n",
    "            columns['Second Starting Material free'] = sm2_free_final\n",
    "\n",
    "    sheet3 = pd.DataFrame(columns)\n",
    "\n",
    "    # Optional renaming\n",
    "    if name_sm1:\n",
    "        sheet3.rename(columns={'Starting Material': name_sm1}, inplace=True)\n",
    "    if name_sm2 and conc_sm2 is not None:\n",
    "        sheet3.rename(columns={'Second Starting Material': name_sm2}, inplace=True)\n",
    "        if ArCl:\n",
    "            sheet3.rename(columns={'Second Starting Material free': name_sm2 + ' free'}, inplace=True)\n",
    "\n",
    "    return sheet1, sheet2, sheet3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62001caf-cfb8-43b0-89e1-bd63c0a8e5be",
   "metadata": {},
   "source": [
    "### Main Function for IR Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d37215e7-7766-4491-bc5e-344ae088b5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to handle file reading, processing, and writing the output\n",
    "def main(input_file, reaction_start_time, ir_start_time, initial_conc_starting_material, initial_conc_second_material, start_material_name='Starting Material', product_name='Product', second_material_name='Second Material'):\n",
    "    file_name_without_ext = os.path.splitext(os.path.basename(input_file))[0]\n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(input_file)\n",
    "    # Assuming the columns are: Time, Starting Material IR, Product IR\n",
    "    time = df.iloc[:, 0]  # Convert time column to datetime \n",
    "    time_in_seconds = convert_time_to_seconds(time)\n",
    "    ir_starting_material = df.iloc[:, 1]\n",
    "    ir_product = df.iloc[:, 2]\n",
    "\n",
    "    if start_material_name in ['ArCl','ArBr']:\n",
    "        ArCl=True\n",
    "    else:\n",
    "        ArCl=False\n",
    "    # Process the IR data\n",
    "    sheet1_data, sheet2_data, sheet3_data = process_ir_data(\n",
    "        time_in_seconds, ir_starting_material, ir_product, reaction_start_time, ir_start_time,\n",
    "        initial_conc_starting_material, initial_conc_second_material,Name_SM1,Name_SM2,time,ArCl\n",
    "    )\n",
    "\n",
    "    # Write to an Excel file with three sheets\n",
    "    output_file = f'{file_name_without_ext}_processed.xlsx'\n",
    "    with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "        sheet1_data.to_excel(writer, sheet_name='Raw IR Data', index=False)\n",
    "        sheet2_data.to_excel(writer, sheet_name='Processed IR Profiles', index=False)\n",
    "        sheet3_data.to_excel(writer, sheet_name='Concentration Profiles', index=False)\n",
    "    \n",
    "    print(f\"Data successfully processed and saved to {output_file}\")\n",
    "    sheet3_csv_name = file_name_without_ext + '_data.csv'\n",
    "    sheet3_data.to_csv(sheet3_csv_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56cb9d4-2055-4eb4-8161-5b833ee9860a",
   "metadata": {},
   "source": [
    "### Explanation of Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc5f188-95c7-49e4-8eaf-06b3e8c91df8",
   "metadata": {},
   "source": [
    "The code does the following:\n",
    "- Time alignment: Aligns the IR time series with the actual reaction start time by calculating a time offset between the IR start and the reaction start. Time is converted into minutes.\n",
    "- IR Trace Assignment: Automatically determines which of the two IR traces corresponds to the starting material (SM) and which to the product (P), based on signal trends (e.g., SM decreases, P increases).\n",
    "- Signal Scaling: Scales both IR traces into concentrations:\n",
    "    - The starting material IR signal is scaled based on initial and final baselines and a known starting concentration.\n",
    "    - The product IR signal is scaled similarly, using its baseline values before and after the reaction.\n",
    "- Optional Second Material Calculation:If a second reactant concentration is provided, the function calculates its decreasing concentration as the reaction proceeds. For aryl chlorides and bromides, the concentration of the free non-protonated amine is also calculated by subtracting two equivalents of product from the initial concentration at each time point. However, this is not necessary for aryl phenyl ether electrophiles.\n",
    "\n",
    "The script then outputs two files:\n",
    "- An xlsx. file with three sheets showing the progression of the data treatment:\n",
    "    - 1: Raw IR trends with a time axis (minutes) set to 0 at the start of the reaction (first amine addition) rather than the start of the IR experiment.\n",
    "    - 2: Scaled IR data (from inputted initial concentration of electrophile, assuming complete conversion to product. Note that for SAKE experiments, this is somewhat incorrect as the final product concentration is lower than that of the initial electrophile concentration due to dilution via additions made over the experiment.\n",
    "    - 3: Cleaned and filtered data, with time starting at 0 (last IR recorded before start of experiment) and with a mass balance column showing the sum of the product and electrophile concentrations across time.\n",
    "- A csv file containing the third sheet of the xlsx. file. This is used as an input for the proper IR scaling done in the Jupyter Notebook script Scaling of IR trends with Calibrated HPLC data.ipynb in the folder Scaling of IR trends with calibrated HPLC Data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e14e9d-ec16-4e88-b450-8a4f0ff92208",
   "metadata": {},
   "source": [
    "### Example of Use for SAKE Experiments (First 2 Experiments of Campaign 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e295044a-19b2-484d-991f-6c8d69dcf495",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_trend_inputs=os.getcwd()+\"\\\\IR trend input data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da526f59-4d34-402a-a152-ea138b978078",
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiments=[]\n",
    "for file in os.listdir(path_to_trend_inputs):\n",
    "    Experiments.append(file[:-14].replace(' ',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d1560f5-3151-43cd-abf3-129653f563f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference between IR start and reaction start (in seconds): -519.0\n",
      "Data successfully processed and saved to C1_E1 IR trends_processed.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = path_to_trend_inputs+'\\\\C1_E1 IR trends.xlsx' \n",
    "    reaction_start_time = '09:33:54'  \n",
    "    ir_start_time = '09:25:15' \n",
    "    initial_conc_starting_material =121.427473\n",
    "    initial_conc_second_material = None  \n",
    "    Name_SM1='4SO2Me-ArOPh'\n",
    "    Name_SM2='4MePip'\n",
    "\n",
    "    main(input_file, ir_start_time,reaction_start_time, initial_conc_starting_material, initial_conc_second_material,Name_SM1,Name_SM2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bda1c10e-db0f-4cda-b8db-bf5558182f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time difference between IR start and reaction start (in seconds): -1152.0\n",
      "Data successfully processed and saved to C1_E2 IR trends_processed.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = path_to_trend_inputs+'\\\\C1_E2 IR trends.xlsx'  \n",
    "    reaction_start_time = '15:48:02'  \n",
    "    ir_start_time = '15:28:50'  \n",
    "    initial_conc_starting_material =124.5646823\n",
    "    initial_conc_second_material = None  \n",
    "    Name_SM1='4SO2Me-ArOPh'\n",
    "    Name_SM2='4MePip'\n",
    "\n",
    "    main(input_file, ir_start_time,reaction_start_time, initial_conc_starting_material, initial_conc_second_material,Name_SM1,Name_SM2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2d188-33ac-444a-8de3-ba1fd66362b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
